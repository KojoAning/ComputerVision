{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import librosa\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    datasets = {\n",
    "    'cv_corpus_url' : 'https://download1514.mediafire.com/kkfvb0kznvwgHV0TJ_H9h5N6TXGzs59Y6Jn4HKNxAbhBV-1TgjNKx-AKkUouCiidWlvdDML7UHWGX0Akq_hmzAqNNP6Xww3H6h5lmh3xy4_-o_V8umkXOc0HbWbZRSfoXL-Kpju01uWmTRI8UBUlUiRyRx8bW_rqWmnlMaJNf3PmMsI/26zyiwi3d4c5nil/cv-corpus-15.0-delta-2023-09-08-en.tar.gz',\n",
    "    'LJ_Speech_url' : 'https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2'\n",
    "    }\n",
    "\n",
    "    cv_corpus_path = os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08-en.tar.gz')\n",
    "    LJ_speech_path = os.path.join(os.getcwd(),'LJSpeech-1.1.tar.bz2')\n",
    "\n",
    "    for data in datasets.keys():\n",
    "        print(f'Downloading {data}')\n",
    "        print(datasets[data])\n",
    "        # requests.get(datasets[data])\n",
    "\n",
    "        if data == 'cv_corpus_url':\n",
    "          response = requests.get(datasets[data])\n",
    "          with open(cv_corpus_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "            print('Done downloading CVcorpus')\n",
    "            try:\n",
    "              print('extracting cvcorpus')\n",
    "              with tarfile.open(cv_corpus_path,'r:gz') as z:\n",
    "                  z.extractall()\n",
    "                  print('Done extracting CVcorpus')\n",
    "            except:\n",
    "                print(\"Unable to complete CVcorpus request\")\n",
    "\n",
    "            os.remove(cv_corpus_path)\n",
    "\n",
    "        elif data == 'LJ_Speech_url':\n",
    "            files = requests.get(datasets[data])\n",
    "            with open(LJ_speech_path, 'wb') as f:\n",
    "              f.write(files.content)\n",
    "            print('Done downloading LJSpeech')\n",
    "            try:\n",
    "              print(\"Extracting LJSpeech\")\n",
    "              with tarfile.open(LJ_speech_path, \"r:bz2\") as f:\n",
    "                  f.extractall()\n",
    "                  print('Done downloading LJ_Speech')\n",
    "            except:\n",
    "                print(\"Unable to complete LJSpeech request\")\n",
    "\n",
    "            os.remove(LJ_speech_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(os.getcwd(),'cv-corpus'))\n",
    "os.makedirs(os.path.join(os.getcwd(),'LJSpeech'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_cv_corpus():\n",
    "  cv_corpus_audio_file_paths = os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08','en','clips')\n",
    "  cv_corpus_audio_files = os.listdir(cv_corpus_audio_file_paths)\n",
    "  for files in cv_corpus_audio_files:\n",
    "    src_path = os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08','en','clips',files)\n",
    "    dst_path = os.path.join(os.getcwd(),'cv-corpus',files)\n",
    "    shutil.move(src_path,dst_path)\n",
    "  shutil.rmtree( os.path.join(os.getcwd(),'cv-corpus-15.0-delta-2023-09-08'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_LJSpeech():\n",
    "  LJSpeech_audio_file_paths = os.path.join(os.getcwd(),'LJSpeech-1.1','wavs',)\n",
    "  LJSpeech_audio_files = os.listdir(LJSpeech_audio_file_paths)\n",
    "  for files in LJSpeech_audio_files:\n",
    "    src_path = os.path.join(os.getcwd(),'LJSpeech-1.1','wavs',files)\n",
    "    dst_path = os.path.join(os.getcwd(),'LJSpeech',files)\n",
    "    shutil.move(src_path,dst_path)\n",
    "  shutil.rmtree( os.path.join(os.getcwd(),'LJSpeech-1.1'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the paths for your audio files\n",
    "class Paths:\n",
    "    LJSpeech: str = os.path.join(os.getcwd(),'LJSpeech')\n",
    "    CVcorpus: str = os.path.join(os.getcwd(),'cv-corpus')\n",
    "    Spectrum_images_train: str = os.path.join(os.getcwd(),'Spectrum_Images','train')\n",
    "    Spectrum_images_valid: str = os.path.join(os.getcwd(),'Spectrum_Images','valid')\n",
    "    CVcorpus_Spectrum_train_images: str = os.path.join(os.getcwd(),'Spectrum_Images','train','CVcorpus')\n",
    "    LJSpeech_Spectrum_train_images: str = os.path.join(os.getcwd(),'Spectrum_Images','train','LJSpeech')\n",
    "    CVcorpus_Spectrum_valid_images: str = os.path.join(os.getcwd(),'Spectrum_Images','valid','CVcorpus')\n",
    "    LJSpeech_Spectrum_valid_images: str = os.path.join(os.getcwd(),'Spectrum_Images','valid','LJSpeech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folders for the different audio files\n",
    "os.makedirs(Paths.CVcorpus_Spectrum_train_images)\n",
    "os.makedirs(Paths.LJSpeech_Spectrum_train_images)\n",
    "os.makedirs(Paths.CVcorpus_Spectrum_valid_images)\n",
    "os.makedirs(Paths.LJSpeech_Spectrum_valid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#function to process audio and generate the spectrum images\n",
    "\n",
    "class Prep_data():\n",
    "    def process_audio(audio_path,save_location,filename):\n",
    "        audio, fs = librosa.load(audio_path)\n",
    "        D = librosa.amplitude_to_db(librosa.stft(audio), ref=np.max)\n",
    "        # Save the spectrogram\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.axis('off')\n",
    "        librosa.display.specshow(D, sr=fs, x_axis='time', y_axis='linear',cmap='viridis')\n",
    "        plt.savefig(save_location+'/'+filename+'.jpg', dpi=300, bbox_inches='tight', pad_inches=0,transparent=True)\n",
    "        plt.close()\n",
    "        print(save_location+'/'+filename+'.jpg')\n",
    "\n",
    "    def crop_image(imagepath):\n",
    "        image = cv.imread(imagepath)\n",
    "        x, y, w, h = 100,50,610,535\n",
    "        cropped_image = image[y:y + h, x:x + w] # Crop the image using the bounding rectangle coordinates\n",
    "        # image =np.array(image)\n",
    "        cv.imwrite(imagepath,cropped_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audios in os.listdir(Paths.CVcorpus)[:300]:\n",
    "    filename = audios[:-4]\n",
    "    Prep_data.process_audio(Paths.CVcorpus+f'/{audios}',Paths.CVcorpus_Spectrum_train_images,filename)\n",
    "    Prep_data.crop_image(Paths.CVcorpus_Spectrum_train_images+'/'+filename+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audios in os.listdir(Paths.CVcorpus)[400:500]:\n",
    "    Prep_data.process_audio(Paths.CVcorpus+f'/{audios}',Paths.CVcorpus_Spectrum_valid_images,filename)\n",
    "    Prep_data.crop_image(Paths.CVcorpus_Spectrum_valid_images+'/'+filename+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audios in os.listdir(Paths.LJSpeech)[:300]:\n",
    "    filename = audios[:-4]\n",
    "    Prep_data.process_audio(Paths.LJSpeech+f'/{audios}',Paths.LJSpeech_Spectrum_train_images,filename)\n",
    "    Prep_data.crop_image(Paths.LJSpeech_Spectrum_train_images+'/'+filename+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audios in os.listdir(Paths.LJSpeech)[400:500]:\n",
    "    Prep_data.process_audio(Paths.LJSpeech+f'/{audios}',Paths.LJSpeech_Spectrum_valid_images,filename)\n",
    "    Prep_data.crop_image(Paths.LJSpeech_Spectrum_valid_images+'/'+filename+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,fill_mode='nearest',horizontal_flip=True,zoom_range=0.5,vertical_flip=True)\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_datagen.flow_from_directory(Paths.Spectrum_images_train,target_size=(300,300),class_mode='binary')\n",
    "valid_images = valid_datagen.flow_from_directory(Paths.Spectrum_images_valid,target_size=(300,300),class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.applications.vgg16.VGG16(include_top=False,weights='imagenet',input_shape=(300,300,3)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorBoard callback\n",
    "log_dir = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_images,validation_data=valid_images,epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
